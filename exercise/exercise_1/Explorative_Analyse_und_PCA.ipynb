{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f35b55",
   "metadata": {},
   "source": [
    "# Arbeitsblatt 1: Explorative Analyse und Hauptkomponentenanalyse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d4461",
   "metadata": {},
   "source": [
    "[TOC](#Inhaltsverzeichnis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5e7cc",
   "metadata": {},
   "source": [
    "## 1. Explorative Analyse des Datensatzes ''Boston Housing''\n",
    "\n",
    "*Boston Housing* ist ein berühmter Datensatz zur Evaluierung von Regressionsalgorithmen. Er enthält 506 Einträge mit jeweils 13 Variablen. Ziel ist es, den Hauspreis (`tgt`) aus den anderen Variablen vorherzusagen. Der Download dieses Datensatzes in einen Pandas-DataFrame wird folgendermaßen durchgeführt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}, pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url     = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols    = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B', 'LSTAT','TGT']\n",
    "boston  = pd.read_csv(url, sep=' ', skipinitialspace=True, header=None, names=cols, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30546e2f",
   "metadata": {},
   "source": [
    "Wichtig für diese Übung ist eine grundlegende Vertrautheit mit den Python-Paketen Numpy und Pandas. Die Abgabe der Aufgabe erfolgt als fertiges IPython-Notebook mit Kommentaren in Markdown.\n",
    "\n",
    "Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5563f",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.1 Explorative Analyse\n",
    "\n",
    "a) Führen Sie für diesen Datensatz eine explorative Analyse wie in der Vorlesung gezeigt mithilfe eines IPython-Notebooks und den Paketen Pandas und Numpy durch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad46af",
   "metadata": {},
   "source": [
    "#### 1.1.1 Darstellung als Pandas-DataFrame\n",
    "\n",
    "Im ersten Schritt wird sich der Datensatz bzw. die ersten 5 Einträge wie im [Vorlesungsbeispiel](../../lecture/01_eda/explorative_analyse.ipynb) gezeigt als Pandas-DataFrame ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d89e89",
   "metadata": {},
   "source": [
    "Zeilenbezeichnungen:\n",
    "- `CRIM` = Kriminalitätsrate\n",
    "- `ZN` = Anteil Wohngebiete\n",
    "- `INDUS` = Anteil Nicht-Einzelhandels-Geschäfte\n",
    "- `CHAS` = Charles River Dummy-Variable\n",
    "- `NOX` = Stickstoffdioxidkonzentration\n",
    "- `RM` = Durchschnittliche Anzahl Räume\n",
    "- `AGE` = Anteil der Eigenheime\n",
    "- `DIS` = Gewichtete Entfernungen zu Beschäftigungszentren\n",
    "- `RAD` = Index der Annehmlichkeiten\n",
    "- `TAX` = Grundsteuer\n",
    "- `PTRATIO` = Schüler-Lehrer-Verhältnis\n",
    "- `B` = Anteil der Schwarzen Bevölkerung\n",
    "- `LSTAT` = Anteil der einkommensschwachen Bevölkerung\n",
    "- `TGT` = Zielvariable (Hauspreis)\n",
    "\n",
    "Erklärung zu den Zeilen siehe (https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e16da",
   "metadata": {},
   "source": [
    "Anschließend lässt sich mittels `shape` die Dimension des DataFrames ausgeben sowie die Spaltennamen mit `columns` anzeigen und die Datentypen mit `dtypes` überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ba5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66800063",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031eb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4c4cfc",
   "metadata": {},
   "source": [
    "#### 1.1.2 Aufbereitung des Datensatzes\n",
    "\n",
    "Im nächsten Schritt wird überprüft, ob der Datensatz fehlende Werte enthält und wie viele Einträge es sind. Dies wird wie im [Vorlesungsbeispiel](../../lecture/01_eda/explorative_analyse.ipynb) mittels `isnull()` und `sum()` durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2ce16",
   "metadata": {},
   "source": [
    "In dem Fall sind keine fehlenden Werte vorhanden und somit diesbezüglich keine weiteren Schritte zur Aufbereitung des Datensatzes notwendig.\n",
    "\n",
    "Dennoch ist es weiterhin notwendig zu prüfen, ob es Duplikate im Datensatz gibt. Dies wird mit der Methode `duplicated()` überprüft. Auch hier sind keine Duplikate vorhanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8fd5f",
   "metadata": {},
   "source": [
    "#### 1.1.3 Explorative Statistiken\n",
    "\n",
    "Im nächsten Schritt werden einige grundlegende Statistiken des Datensatzes ausgegeben, wie z.B. Mittelwert, Median, Standardabweichung, Minimum und Maximum. Dies kann mit der Methode `describe()` von Pandas durchgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbce3bc",
   "metadata": {},
   "source": [
    "Anschließen soll eine Streumatrix erstellt werden welche im Aufgabenteil b) weiterverwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(boston, figsize=(14, 14), diagonal='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f1524",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 Analyse der Streumatrix\n",
    "\n",
    "b) Beantworten Sie anhand der Darstellung der Streumatrix folgende Fragen: Welche der Variablen sind kategorisch? Welche der Variablen eignen sich gut zur Vorhersage des Hauspreises und warum? Welche dieser Variablen sind miteinander korreliert? Welche sind daher Kandidaten, die man evtl. weglassen könnte? (Beantwortung bitte als Markup in Notebook eintragen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba28505",
   "metadata": {},
   "source": [
    "#### 1.2.1 Kategorische Variablen identifizieren\n",
    "\n",
    "Um zu prüfen welche Variablen im Datensatz kategorisch sind, also diskret und mit wenigen verschiedenen Ausprägungen, können die Datentypen und die Anzahl der eindeutigen Werte jeder Spalte untersucht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.dtypes\n",
    "boston.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23976b",
   "metadata": {},
   "source": [
    "Hieraus gehen folgende Variablen als kategorisch hervor:\n",
    "- `CHAS`: Diese Variable ist eine Dummy-Variable (0 oder 1)\n",
    "- `RAD`: Diese Variable hat eine begrenzte Anzahl von eindeutigen Werten und repräsentiert verschiedene Indizes der Annehmlichkeiten.="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1187ff",
   "metadata": {},
   "source": [
    "#### 1.2.2 Vorhersage des Hauspreises anhand der Streumatrix\n",
    "\n",
    "Die Streumatrix zeigt die paarweisen Beziehungen zwischen den Variablen im Datensatz. Um zu beurteilen, welche Variablen gut zur Vorhersage des Hauspreises (`TGT`) geeignet sind, sollte man nach Variablen suchen, die eine starke Korrelation mit `TGT` aufweisen. In der Streumatrix sind solche Beziehungen durch eine klare lineare oder nicht-lineare Verteilung der Punkte erkennbar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85dd9db",
   "metadata": {},
   "source": [
    "Hierbei ist es wahrscheinlich hilfreich sich den Trend der Punktewolke anzusehen und zu beurteilen ob ein linearer oder nicht-linearer Zusammenhang besteht. Hierzu wurden ein einzelner Scatterplot für jedes Feature gegen die Zielvariable `TGT` erstellt und eine Regressionslinie hinzugefügt um den Trend besser erkennen zu können (die Abbildung am besten in einem separaten Fenster betrachten :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in boston.columns if c != 'TGT']\n",
    "n = len(features)\n",
    "\n",
    "# create subplots for each feature\n",
    "fig, axs = plt.subplots(1, n, figsize=(8*n, 8), sharey=True, constrained_layout=True)\n",
    "\n",
    "if n == 1:\n",
    "    axs = [axs]\n",
    "# plot scatter plots with regression lines for each feature against TGT\n",
    "for ax, f in zip(axs, features):\n",
    "    ax.scatter(boston[f], boston['TGT'], s=20, alpha=0.6)\n",
    "    ax.set_xlabel(f)\n",
    "    ax.set_ylabel('TGT')\n",
    "    m, b = np.polyfit(boston[f], boston['TGT'], 1)\n",
    "    ax.plot(boston[f], m*boston[f] + b, color='red', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf07d7",
   "metadata": {},
   "source": [
    "Aus der visuellen Analyse der Scatterplots lassen sich folgende Zusammenhänge erkennen:\n",
    "- `RM` (durchschnittliche Anzahl Räume): Zeigt eine starke positive Korrelation mit `TGT`. Mehr Räume führen tendenziell zu höheren Hauspreisen.\n",
    "- `LSTAT` (Anteil der einkommensschwachen Bevölkerung): Zeigt eine starke negative Korrelation mit `TGT`. Ein höherer Anteil einkommensschwacher Bevölkerung ist mit niedrigeren Hauspreisen verbunden.\n",
    "- `NOX` (Stickstoffdioxidkonzentration): Zeigt eine moderate negative Korrelation mit `TGT`. Höhere NOX-Werte sind mit niedrigeren Hauspreisen verbunden (was so viel heißt wie umso schlechter die Luftqualität ist umso niedriger die Hauspreise).\n",
    "\n",
    "**Fazit:** Die Variablen `RM`, `LSTAT` und `NOX` eignen sich gut zur Vorhersage des Hauspreises aufgrund ihrer starken Korrelation mit der Zielvariable `TGT`. Bei den anderen Variablen (von den kategorischen abgesehen) lassen sich zwar auch teilweise zusammenhänge erkennen, diese sind jedoch weniger stark ausgeprägt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a88e75",
   "metadata": {},
   "source": [
    "#### 1.2.3 Korrelation zwischen Variablen\n",
    "\n",
    "Um zu überprüfen, welche Variablen miteinander korreliert sind, kann die Korrelationsmatrix des Datensatzes berechnet werden. Variablen mit hoher Korrelation (z.B. > 0.8 oder < -0.8) könnten Kandidaten sein, die man evtl. weglassen könnte, um Redundanz zu vermeiden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b45d5f",
   "metadata": {},
   "source": [
    "Um dies visuell besser darzustellen eignet sich die Heatmap einer Korrelationsmatrix welche mittels des Pakets Seaborn erstellt werden kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "corr = boston.corr()\n",
    "\n",
    "# plot heatmap of correlation matrix using seaborn\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Korrelations-Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a797a6",
   "metadata": {},
   "source": [
    "Die Heatmap bestätigt die zuvor identifizierten Korrelationen zwischen den Variablen und der Zielvariable `TGT`. Zusätzlich zeigt sie auch Korrelationen zwischen den unabhängigen Variablen selbst auf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70dc11",
   "metadata": {},
   "source": [
    "Da das dank KI alles so \"leicht von der Hand geht\" wurde mal noch wie im [Vorlesungsbeispiel](../../lecture/00_intro/cor_dataland.ipynb) gezeigt der Korrelationskoeffizient nach Pearson für die Variable mit der höchsten Korrelation (`RM`) mit der Zielvariable `TGT` berechnet. Der ermittelte Wert stimmt dabei mit dem aus der Korrelationsmatrix überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ace4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, p = pearsonr(boston['RM'], boston['TGT'])\n",
    "print(f\"Korrelationskoeffizient nach Pearson (scipy) RM/TGT: = {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f82100",
   "metadata": {},
   "source": [
    "#### 1.2.4 Unnötige Variablen\n",
    "\n",
    "Die gezeigten Analysen zeigen, dass einige Variablen wie z.B. `RAD` und `TAX` eine hohe Korrelation aufweisen (eine bessere Verkehrsanbindung führt oft zu höheren Grundsteuern), diese aber im Bezug auf die Zielvariable `TGT` nur eine moderate Korrelation zeigen. Jedoch stellen sich auch im Bezug auf die Zielvariable `TGT` einige Variablen wie z.B. `ZN`, `DIS` oder `B` (#BlackLiveMatters) als eher irrelevant heraus. Das zeigt sehr gut das eine explorative Analyse wichtig ist um die richtigen Features für den eigentlichen Use-Case auszuwählen.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd83b7",
   "metadata": {},
   "source": [
    "### 1.3 Dokumentation der Systemkonfiguration\n",
    "\n",
    "c) Die Dokumentation der eingesetzten Systemkonfiguration und Paketversionen erfolgt durch das Skript `version_information` von R. H. Johanson. Installation über"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install version-information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39c877",
   "metadata": {},
   "source": [
    "Im Notebook-Header muss das Paket importiert werden über"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed840117",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext version_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830f458",
   "metadata": {},
   "source": [
    "Danach kann die Information über die Systemkonfiguration dargestellt werden durch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "%version_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983e99f",
   "metadata": {},
   "source": [
    "Sollen zusätzlich Versionsinformationen über die eingesetzten Pakete dargestellt werden, verwendet man (hier z.B. Numpy und Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad71ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%version_information numpy, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c89db",
   "metadata": {},
   "source": [
    "Diese Zeilen sollten immer am Ende des Notebooks aufgerufen werden, um ein Mindestmaß an Reproduzierbarkeit sicherzustellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb091f2",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e863242",
   "metadata": {},
   "source": [
    "## 2. Datenvorverarbeitung mit Pandas: Food Nutrient Database\n",
    "\n",
    "Diese Aufgabe befasst sich mit einer deutlich umfangreicheren Datenbank des *U.S. Department of Agriculture*, aufbereitet im Format JSON von A. Williams, zum Thema Nährstoffgehalt von Nahrungsmitteln. Sie enthält 6636 Einträge für Nahrungsmittel, alle in Form von JSON-Records, wie z.B.:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": 21441,\n",
    "    \"description\": \"KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY, Wing,\n",
    "        meat and skin with breading\", \"tags\": [\"KFC\"],\n",
    "    \"manufacturer\": \"Kentucky Fried Chicken\", \"group\": \"Fast Foods\",\n",
    "    \"portions\": [ \n",
    "        {\n",
    "            \"amount\": 1,\n",
    "            \"unit\": \"wing , with skin\",\n",
    "            \"grams\": 68.0 \n",
    "        },\n",
    "        ...\n",
    "    ], \n",
    "    \"nutrients\": [\n",
    "        {\n",
    "            \"value\": 20.8,\n",
    "            \"units\": \"g\", \n",
    "            \"description\": \"Protein\",\n",
    "            \"group\": \"Composition\" \n",
    "        },\n",
    "        ... \n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Ziel der Analyse in dieser Übung ist es, eine explorative Analyse des Gehalts des Spurenelementes Zink in den verschiedenen Nahrungsmitteln durchzuführen. Notwendig dafür sind etwas aufwändigere, aber für die Datenanlyse typische Manipulationen mit Pandas sowie der\n",
    "Einsatz zusätzlicher Python-Standardbibliotheken zum Download und der Verarbeitung von Zip- und JSON-Dateien.\n",
    "\n",
    "Aufgaben:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f56ba8",
   "metadata": {},
   "source": [
    "### 2.1 Laden und Einlesen der Datenbank\n",
    "\n",
    "a) Laden Sie die Datenbank als zip-File aus Moodle herunter und lesen Sie dieses File direkt in ein neues Notebook ein. Die bisher verwendete Pandas-Methode `read_csv()` funktioniert für JSON-Files leider nicht. Das heruntergeladene File wird stattdessen mithilfe des Pythonmoduls `zipfile` entpackt und dem Python-Befehl `open()` eingelesen. Die Umwandlung des JSON-Formates in ein geeignetes Python-Format erfolgt mit einem weiteren Modul der Python-Standardlibrary, `json`, hier mithilfe der Funktion `json.load()`. Lesen Sie dazu die zugehörigen, auf dem Web bzw. Stackoverflow verfügbaren Anleitungen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7bab3",
   "metadata": {},
   "source": [
    "#### 2.1.1 Einlesen und Entpacken des Zip-Files\n",
    "\n",
    "Wie im Folgenden gezeigt, wird das Zip-File entpackt und die JSON-Daten eingelesen. Hierbei wurde sich nach einigem herumprobieren dafür entschieden, die in der JSON Datei vorhanden Dictionaries in einem übergeordneten Dictionary zu speichern, wobei die bereits vorhanden IDs der JSON Records als Keys verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed92e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "\n",
    "# path to the zip file\n",
    "zip_file_path = 'foods-2011-10-03.json.zip'\n",
    "\n",
    "records = {}\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
    "\tfile_list = [n for n in z.namelist() if not n.endswith('/')]  # nur Dateien, keine Verzeichnisse\n",
    "\tfor file_name in file_list:\n",
    "\t\twith z.open(file_name) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tif isinstance(data, list):\n",
    "\t\t\t\tfor record in data:\n",
    "\t\t\t\t\trecords[record['id']] = record\n",
    "\n",
    "print(f\"Anzahl der eingelesenen JSON-Records: {len(records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864beaf",
   "metadata": {},
   "source": [
    "prüfen ob das so geklappt hat wie gewünscht "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"type of records: {type(records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27217d8",
   "metadata": {},
   "source": [
    "Anzeigen aller in der Datenbank enthaltenen Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "records.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082be57",
   "metadata": {},
   "source": [
    "Und dann mal noch schauen ob der aus der Aufgabenbeschreibung genannte Eintrag mit der ID 21441 auch wirklich Fried Chicken ist :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb085f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records.get(21441)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae60d4",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bee2f",
   "metadata": {},
   "source": [
    "### 2.2 Aufbereitung der Datenbank\n",
    "\n",
    "b) Die Datenbank steht nun in Form einer Liste aus 6636 Python-Dictionaries zu Verfügung. Jedes Dictionary enthält Angaben zu einem Nahrungsmittel. Greifen Sie sich ein beliebiges Nahrungsmittel heraus und lassen sich die Namen der Einträge mit der Methode `dict.keys()` anzeigen. Einer der Einträge enthält die enthaltenen Nährstoffe (`nutrients`), ebenfalls als Dictionary. Lassen Sie sich wiederum einen beliebigen Eintrag der Nährstoffliste anzeigen. Es sollte auffallen, dass manche Feldnamen doppelt vorkommen.\n",
    "\n",
    "Teile dieser hierarchischen Struktur sollen nun in eine einheitliche Tabelle umgewandelt werden, um eine explorative Analyse durchführen zu können.\n",
    "\n",
    "Vorgehensweise:\n",
    "\n",
    "* Kopieren Sie zunächst die Felder `description`,`group`,`id`,`manufacturer` in einen eigenen DataFrame `info`, sowie alle Nährstofflisten in ein Array von DataFrames, wobei Sie an jeden DataFrame die entsprechende ID des Nahrungsmittels als eigene Spalte anhängen.\n",
    "* Dieses Array wird mithilfe der Funktion `pandas.concat()` zu einem großen DataFrame nutrients (389355 Einträge) vereinigt.\n",
    "* Entfernen Sie alle Duplikate aus diesem DataFrame.\n",
    "* Bevor beide DataFrames vereinigt werden können, gibt es noch ein Problem: beide enthalten Felder mit dem Namen `description` und `group` (s.o.). Benennen Sie diese daher mithilfe von DataFrame.rename() in eindeutige Namen um.\n",
    "* Vereinigen Sie beide DataFrames mit `pandas.merge(nutrients, info, on=’id’, how=’outer’)` anhand der Nahrungsmittel-ID.\n",
    "\n",
    "Überprüfen Sie das Ergebnis jeder Manipulation mit `DataFrame.head()``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310ad0a",
   "metadata": {},
   "source": [
    "#### 2.2.1 Anzeigen eines beliebigen Eintrags der Nährstoffliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "records.get(11444).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "#record = records.get(11444)\n",
    "record = records.get(21441)\n",
    "\n",
    "pprint.pprint(record.get('nutrients'), width=120, sort_dicts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a9b243",
   "metadata": {},
   "source": [
    "#### 2.2.2 Umwandeln in DataFrames\n",
    "\n",
    "##### DataFrames erstellen\n",
    "\n",
    "Kopieren Sie zunächst die Felder `description`,`group`,`id`,`manufacturer` in einen eigenen DataFrame `info`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804edc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "info = pd.DataFrame([\n",
    "    {\n",
    "        'id': r.get('id'),\n",
    "        'description': r.get('description'),\n",
    "        'group': r.get('group'),\n",
    "        'manufacturer': r.get('manufacturer')\n",
    "    }\n",
    "    for r in records.values()\n",
    "])\n",
    "\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11ee74",
   "metadata": {},
   "source": [
    "... sowie alle Nährstofflisten in ein Array von DataFrames, wobei Sie an jeden DataFrame die entsprechende ID des Nahrungsmittels als eigene Spalte anhängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_dfs = []\n",
    "for r in records.values():\n",
    "    nd = pd.DataFrame(r.get('nutrients', []))\n",
    "    if not nd.empty:\n",
    "        nd['id'] = r['id']\n",
    "        nutrient_dfs.append(nd)\n",
    "        \n",
    "nutrient_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68958938",
   "metadata": {},
   "source": [
    "Dieses Array wird mithilfe der Funktion `pandas.concat()` zu einem großen DataFrame nutrients (389355 Einträge) vereinigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.concat(nutrient_dfs, ignore_index=True)\n",
    "print(nutrients.shape) # show the shape of the combined DataFrame (should be (389355, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e84a7",
   "metadata": {},
   "source": [
    "Entfernen Sie alle Duplikate aus diesem DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.drop_duplicates(inplace=True) # inplace=True to modify the DataFrame directly\n",
    "print(nutrients.shape) # show the shape after removing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb5a0a",
   "metadata": {},
   "source": [
    "Bevor beide DataFrames vereinigt werden können, gibt es noch ein Problem: beide enthalten Felder mit dem Namen `description` und `group` (s.o.). Benennen Sie diese daher mithilfe von DataFrame.rename() in eindeutige Namen um. Dies soll nochmal anhand der beiden DataFrames `info` und `nutrients` gezeigt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5eb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.rename(columns={'description': 'nutrient_description', 'group': 'nutrient_group'}, inplace=True)\n",
    "info.rename(columns={'description': 'food_description', 'group': 'food_group'}, inplace=True)\n",
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f69224",
   "metadata": {},
   "source": [
    "Vereinigen Sie beide DataFrames mit `pandas.merge(nutrients, info, on=’id’, how=’outer’)` anhand der Nahrungsmittel-ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(nutrients, info, on='id', how='outer') # how='outer' to keep all records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731decf6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907279ad",
   "metadata": {},
   "source": [
    "### 2.3 Untersuchung des Spurenelements Zink\n",
    "\n",
    "c) Nun sind die Daten bereit für die Untersuchung auf das Spurenelement Zink (Feldname: `Zinc, Zn`). Lesen Sie dazu alle Tabelleneinträge mithilfe einer geeigneten Indizierung in einen DataFrame aus, der nur Einträge zum Nährstoff Zink enthält..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32f5dd",
   "metadata": {},
   "source": [
    "#### 2.3.1 Auslesen der Zink-Einträge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc51258",
   "metadata": {},
   "outputs": [],
   "source": [
    "zn = pd.DataFrame(df[df['nutrient_description'] == 'Zinc, Zn'])\n",
    "zn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "zn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6185ae",
   "metadata": {},
   "source": [
    "Eine Untersuchung der Daten hat ergeben, dass Einträge zum Nährstoff Zink in `mg` vorliegen weshalb keine weitere Verarbeitung erforderlich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f3fe7",
   "metadata": {},
   "source": [
    "#### 2.3.2 Explorative Statistiken des Zinkgehalts\n",
    "\n",
    "... Daraus wählen Sie wiederum die Spalte mit dem Zinkgehalt in mg (`value`) aus und stellen dafür ein Histogramm und eine Liste deskriptiver Statistiken dar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52d06a",
   "metadata": {},
   "source": [
    "##### 2.3.2.1 Histogramm des Zinkgehalts in mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# histogram of zinc content in mg\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(zn['value'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Zinc Content (mg)')\n",
    "plt.xlabel('Zinc Content (mg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d82290",
   "metadata": {},
   "source": [
    "##### 2.3.2.2 Deskriptive Statistiken des Zinkgehalts in mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# basic stuff like mean, median, std, min, max, percentiles\n",
    "desc = zn['value'].describe()\n",
    "print(\"\\nDeskriptive Statistiken:\")\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the variance (std^2), skewness, and kurtosis\n",
    "variance = np.var(zn['value'].dropna())\n",
    "skewness = stats.skew(zn['value'].dropna())\n",
    "kurtosis = stats.kurtosis(zn['value'].dropna())\n",
    "print(f\"\\nVarianz: {variance:.4f}\")\n",
    "print(f\"Schiefe: {skewness:.4f}\")\n",
    "print(f\"Kurtosis: {kurtosis:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd1a55",
   "metadata": {},
   "source": [
    "##### 2.3.2.3 Visualisierung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b888b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot(zn['value'].dropna(), vert=False, showmeans=True, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='black'),\n",
    "            medianprops=dict(color='orange'),\n",
    "            meanprops=dict(marker='D', markeredgecolor='red', markerfacecolor='red'))\n",
    "plt.xlabel('Zink (mg)')\n",
    "plt.title('Boxplot des Zinkgehalts (mg)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f33733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "vals = zn['value'].dropna()\n",
    "n = len(vals)\n",
    "variance = vals.var(ddof=1)\n",
    "std = vals.std(ddof=1)\n",
    "skewness = st.skew(vals)\n",
    "kurtosis = st.kurtosis(vals)  # Fisher: 0 für Normalverteilung\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1) Histogramm + KDE (oben links)\n",
    "ax = axs[0, 0]\n",
    "sns.histplot(vals, bins=50, kde=True, color='skyblue', ax=ax)\n",
    "ax.axvline(vals.mean(), color='red', linestyle='--', label=f'Mean {vals.mean():.2f}')\n",
    "ax.axvline(vals.median(), color='orange', linestyle='-', label=f'Median {vals.median():.2f}')\n",
    "ax.set_title('Histogramm + KDE')\n",
    "ax.set_xlabel('Zink (mg)')\n",
    "ax.legend()\n",
    "\n",
    "# 2) Violinplot + inner box (oben rechts)\n",
    "ax = axs[0, 1]\n",
    "sns.violinplot(x=vals, inner='quartile', color='lightgreen', ax=ax)\n",
    "ax.set_title('Violinplot (Verteilung, Median, Quartile)')\n",
    "ax.set_xlabel('Zink (mg)')\n",
    "\n",
    "# 3) Q-Q-Plot gegen Normalverteilung (unten links)\n",
    "ax = axs[1, 0]\n",
    "st.probplot(vals, dist='norm', plot=ax)\n",
    "ax.set_title('Q‑Q‑Plot vs Normalverteilung')\n",
    "\n",
    "# 4) Textbox mit Kennzahlen und kurzer Interpretation (unten rechts)\n",
    "ax = axs[1, 1]\n",
    "ax.axis('off')\n",
    "text = (\n",
    "    f\"n = {n}\\n\"\n",
    "    f\"Mean = {vals.mean():.3f} mg\\n\"\n",
    "    f\"Median = {vals.median():.3f} mg\\n\"\n",
    "    f\"Varianz (sample) = {variance:.3f}\\n\"\n",
    "    f\"Std (sample) = {std:.3f}\\n\"\n",
    "    f\"Skewness = {skewness:.3f}\\n\"\n",
    "    f\"Kurtosis (Fisher) = {kurtosis:.3f}\\n\\n\"\n",
    "    \"Interpretation:\\n\"\n",
    "    \"- Skewness > 0 → rechtssteil / langer rechter Schwanz\\n\"\n",
    "    \"- Kurtosis > 0 → stärkere Ausreißer / schwerere Tails als Normal\\n\"\n",
    ")\n",
    "ax.text(0.01, 0.98, text, va='top', ha='left', fontsize=11, family='monospace')\n",
    "\n",
    "plt.suptitle('Zink: Verteilung, Varianz, Schiefe und Kurtosis', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd315d27",
   "metadata": {},
   "source": [
    "#### 2.3.3 Die Edamer-Frage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6207cee6",
   "metadata": {},
   "source": [
    "... Finden Sie in Ihrer Tabelle Edamer (`Cheese, edam`). Hat Edamer einen überdurchschnittlichen Zinkgehalt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find data frame entries where food_description contains 'Cheese, edam'\n",
    "cheese_edam = zn[zn['food_description'].str.contains('Cheese, edam', case=False, na=False)]\n",
    "cheese_edam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_mean = cheese_edam['value'].mean() # not necessary to get mean cause only one edam entry\n",
    "zn_mean = zn['value'].mean()\n",
    "\n",
    "print(f\"Durchschnittlicher Zinkgehalt von Edamer: {edam_mean:.2f} mg\\nDurchschnitt aller Nahrungsmittel: {zn_mean:.2f} mg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428879c",
   "metadata": {},
   "source": [
    "Haben mehr als 75% aller Nahrungsmittel einen kleineren Zinkgehalt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller = (zn['value'] < edam_mean).sum()\n",
    "print(f\"Anzahl der Nahrungsmittel mit kleinerem Zinkgehalt als Edamer: {smaller}\")\n",
    "print(f\"Haben mehr als 75% aller Nahrungsmittel einen kleineren Zinkgehalt als Edamer? {'Ja' if smaller > 0.75 * len(zn) else 'Nein'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916adf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(zn['value'].dropna(), bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Zinc Content (mg)')\n",
    "plt.xlabel('Zinc Content (mg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.axvline(edam_mean, color='red', linestyle='--', label=f'Edamer Mean {edam_mean:.2f} mg')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1af19a",
   "metadata": {},
   "source": [
    "Welches Nahrungsmittel hat den maximalen Zinkgehalt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zn_max = zn.get(zn['value'] == zn['value'].max())\n",
    "zn_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e6056",
   "metadata": {},
   "source": [
    "Alternativ lässt sich ein Eintrag in einem Pandas Data-Frame mittels der Methode `loc[]` finden, indem man den Zeilenindex angibt, der mit `idxmax()` für die Spalte `value` des DataFrames `zn` ermittelt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4884fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = zn.loc[zn['value'].idxmax()]\n",
    "max_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc722280",
   "metadata": {},
   "source": [
    "und noch eine entscheidende Frage die hier noch fehlt, hat Edamer mehr Zink als andere Käsesorten im Durchschnitt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfde976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheese = zn[zn['food_description'].str.contains('Cheese', case=False, na=False)]\n",
    "cheese.head()\n",
    "\n",
    "cheese_mean = cheese['value'].mean()\n",
    "print(f\"Durchschnittlicher Zinkgehalt von Käse: {cheese_mean:.2f} mg\\nDurchschnitt Edamer: {edam_mean:.2f} mg\\nDurchschnitt aller Nahrungsmittel: {zn_mean:.2f} mg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8ee87",
   "metadata": {},
   "source": [
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce2f6a",
   "metadata": {},
   "source": [
    "## 3. Implementierung der Hauptkomponentenanalyse\n",
    "\n",
    "Wir beginnen zunächst mit einem schon bekannten Datensatz *Boston Housing*. Zur praktischen Berechnung der Hauptkomponentenanalyse gehen Sie folgt vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}, pandas version: {pd.__version__}\")\n",
    "\n",
    "url     = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols    = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B', 'LSTAT','TGT']\n",
    "boston  = pd.read_csv(url, sep=' ', skipinitialspace=True, header=None, names=cols, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8b880",
   "metadata": {},
   "source": [
    "1. Gegeben eine Menge von $n$ $d$-dimensionalen Datenpunkten $\\mathbf{x}_i$, berechnen Sie zuerst deren Mittelwert $\\boldsymbol{\\mu}_x = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i$ für jedes einzelne Merkmal und ziehen ihn von allen Datenpunkten ab (Zentrierung).\n",
    "2. Normieren Sie dann alle Merkmale so, dass sie eine Varianz von 1 haben. Dieser Schritt ist optional, aber meist vorteilhaft.\n",
    "3. Kopieren Sie alle $\\mathbf{x}_i$ als Reihen in eine $n \\times d$-Matrix $X$, die sog. Daten- oder Designmatrix.\n",
    "4. Zur Lösung des Eigenwertproblens berechnen Sie die Singulärwertzerlegung von $X$ (z.B. mit `numpy.linalg.svd()`): $$ X = UDV^\\top $$\n",
    "Wer nicht weiß, was eine Singuärwertzerlegung ist oder macht, der lese bitte in den entsprechenden Wikipedia-Einträgen nach. Im Prinzip könnte man auch direkt die Eigenwerte der Kovarianzmatrix (s. Folie 12) berechnen (z.B. mit `numpy.linalg.eig()`), diese Methode ist aber meist aufwändiger und numerisch weniger stabil.\n",
    "5. Die ersten $r$ Basisvektoren $\\mathbf{q}_i$  (d.h die ersten $r$ Hauptkomponenten) sind die ersten $r$ Spalten der orthogonalen $d \\times d$-Matrix $V$.\n",
    "6. Die Projektionen $a_i$ der Daten $\\mathbf{x}_i$ auf die ersten $r$ Basisvektoren $\\mathbf{q}_i$ (d.h die neuen Variablenwerte im neuen Koordinatensystem) sind die die ersten $r$ Spalten der $n \\times d$-Matrix $UD$.\n",
    "7. Die Standardabweichungen entlang der Hauptkomponenten $\\mathbf{q}_i$ sind die Diagonalelemente der Diagonalmatrix $D$ geteilt durch $\\sqrt{n - 1}$.\n",
    "\n",
    "Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19cc61",
   "metadata": {},
   "source": [
    "a) Implementieren Sie ein Python-Modul, das eine Funktion zur Hauptkomponentenanalyse nach obigem Schema zur Verfügung stellt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f57c01",
   "metadata": {},
   "source": [
    "b) Testen Sie Ihr Modul innerhalb eines IPython-Notebooks am Datensatz *Boston Housing*. Lassen Sie dabei die Variable `TGT` weg. Stellen Sie Ihre Ergebnisse in einer Tabelle mit den Eigenwerten der Kovarianzmatrix (Achtung: die Diagonalelemente von $D$ müssen dafür quadriert und durch n − 1 geteilt werden. Warum?), dem Anteil der zugehörigen Hauptkomponente an an der Gesamtvarianz (“erklärte Varianz”) und der kumulativen erklärten Varianz dar, d.h. welchen Varianzanteil die ersten $n$ Komponenten zusammen erklären. Wieviele Dimensionen können Sie weglassen, wenn Sie 10%, 5% und 1% Fehler bei der Dimensionsreduktion zulassen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e92aa8",
   "metadata": {},
   "source": [
    "c) Berechnen Sie die Matrix der Korrelationskoeffizienten für die transformierten Variablen und interpretieren Sie das Ergebnis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f4b48",
   "metadata": {},
   "source": [
    "d) Berechnen Sie den Korrelationskoeffizienten der Projektionen auf die ersten drei Hauptkomponenten mit den ursprünglichen Variablen. Interpretieren Sie Ihr Ergebnis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267adfdb",
   "metadata": {},
   "source": [
    "e. Stellen Sie die ersten beiden der neuen Variablen als Scatterplot dar (am besten in Pandas-Dataframe importieren). Plotten Sie dabei alle Datenpunkte mit einem Hauspreis oberhalb des Medians aller Hauspreise in einer anderen Farbe als die Datenpunkte unterhalb. Eignen sich die beiden neuen Variablen zur Vorhersage des Hauspreises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a42406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
