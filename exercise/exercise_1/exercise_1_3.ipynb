{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ce2f6a",
   "metadata": {},
   "source": [
    "## 3. Implementierung der Hauptkomponentenanalyse\n",
    "\n",
    "Wir beginnen zunächst mit einem schon bekannten Datensatz *Boston Housing*. Zur praktischen Berechnung der Hauptkomponentenanalyse gehen Sie folgt vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}, pandas version: {pd.__version__}\")\n",
    "\n",
    "url     = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols    = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B', 'LSTAT','TGT']\n",
    "boston  = pd.read_csv(url, sep=' ', skipinitialspace=True, header=None, names=cols, index_col=False)\n",
    "\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791f981",
   "metadata": {},
   "source": [
    "Ausschließen der Zielvariable `TGT` aus dem Datensatz, sowie katgorische Variablen (`CHAS`, `RAD`) ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = boston.drop(columns=['CHAS', 'RAD', 'TGT'])  # drop categorical and target variable\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8b880",
   "metadata": {},
   "source": [
    "1. Gegeben eine Menge von $n$ $d$-dimensionalen Datenpunkten $\\mathbf{x}_i$, berechnen Sie zuerst deren Mittelwert $\\boldsymbol{\\mu}_x = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i$ für jedes einzelne Merkmal und ziehen ihn von allen Datenpunkten ab (Zentrierung).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e8be3",
   "metadata": {},
   "source": [
    "Mittels pandas `mean()` Funktion kann der Mittelwert für jedes Feature einfach berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = boston.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc08d34",
   "metadata": {},
   "source": [
    "Ebenso kann die Zentrierung des Datensatzes durch einfache Subtraktion des Mittelwerts von jedem Eintrag durchgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db874c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_centered = boston - mean\n",
    "boston_centered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efef061",
   "metadata": {},
   "source": [
    "2. Normieren Sie dann alle Merkmale so, dass sie eine Varianz von 1 haben. Dieser Schritt ist optional, aber meist vorteilhaft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c118bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_normalized = boston_centered / boston.std()\n",
    "boston_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7221e",
   "metadata": {},
   "source": [
    "Vor dem nächsten Schritt noch Prüfen oder der Mittelwert und die Zentrierung korrekt durchgeführt wurden. Der Mittelwert sollte jetzt für alle Features um die 0 liegen, und die Standardabweichung sollte 1 sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = boston_normalized.mean()\n",
    "std_vals = boston_normalized.std()\n",
    "print(\"Mittelwerte nach Normalisierung:\\n\", mean_vals)\n",
    "print(\"Standardabweichungen nach Normalisierung:\\n\", std_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06af463",
   "metadata": {},
   "source": [
    "3. Kopieren Sie alle $\\mathbf{x}_i$ als Reihen in eine $n \\times d$-Matrix $X$, die sog. Daten- oder Designmatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d411326",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_normalized.to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da9426c",
   "metadata": {},
   "source": [
    "4. Zur Lösung des Eigenwertproblens berechnen Sie die Singulärwertzerlegung von $X$ (z.B. mit `numpy.linalg.svd()`): $$ X = UDV^\\top $$\n",
    "Wer nicht weiß, was eine Singuärwertzerlegung ist oder macht, der lese bitte in den entsprechenden Wikipedia-Einträgen nach. Im Prinzip könnte man auch direkt die Eigenwerte der Kovarianzmatrix (s. Folie 12) berechnen (z.B. mit `numpy.linalg.eig()`), diese Methode ist aber meist aufwändiger und numerisch weniger stabil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, Vt = np.linalg.svd(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249c8bc",
   "metadata": {},
   "source": [
    "Die Matrix $X$ ist definiert als:\n",
    "$$\n",
    "X \\in \\reals^{m \\times n} \\text{ mit Rang r}\n",
    "$$\n",
    "In unserem Fall also eine Matrix $X \\in \\reals^{506 \\times 11}$ (ohne die Zielvariable und die kategorischen Variablen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2b49d",
   "metadata": {},
   "source": [
    "Die Matrix $U$ ist per Definition orthogonal und hat die Dimension $m \\times m$. Das bedeutet, Ihre Inverse ist gleich ihrer Transponierten: $U^{-1} = U^\\top$. Dies soll hier mal beispielhaft geprüft werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_inv = np.linalg.inv(U)\n",
    "U_T = U.T\n",
    "print(f\"U_inv ist gleich U_T?: {np.allclose(U_inv, U_T)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c960c",
   "metadata": {},
   "source": [
    "Äquivalent dazu ist die Überprüfung, ob das Produkt von $U$ und $U^\\top$ die Einheitsmatrix ergibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = np.dot(U, U_T)\n",
    "print(f\"Produkt von U und U_T ist Einheitsmatrix?: {np.allclose(prod, np.eye(U.shape[0]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17485919",
   "metadata": {},
   "source": [
    "Die Matrix $V$ ist ebenfalls orthogonal und hat die Dimension $n \\times n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print Vt as matrix with its values to three decimal places\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "print(Vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555ee3e",
   "metadata": {},
   "source": [
    "Die Diagonalmatrix $D$ enthält die Singulärwerte von $X$ in absteigender Reihenfolge auf der Diagonalen und hat die Dimension $m \\times n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf59064",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567bce54",
   "metadata": {},
   "source": [
    "5. Die ersten $r$ Basisvektoren $\\mathbf{q}_i$  (d.h die ersten $r$ Hauptkomponenten) sind die ersten $r$ Spalten der orthogonalen $d \\times d$-Matrix $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acbd67",
   "metadata": {},
   "source": [
    "Die Hauptkomponenten sind also die ersten $r$ **Spalten (*columns*)** der Matrix $V$ oder alternativ der ersten $r$ **Zeilen (*rows*)** der Matrix $V^\\top$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9344fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape\n",
    "\n",
    "# set number of principal components to keep\n",
    "r = 3\n",
    "\n",
    "# get the first r columns of Vt (which correspond to the first r principal components)\n",
    "Q = Vt.T[:, :r] # transpose Vt to get V, then take first r columns [row_min : row_max, col_min : col_max]\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc79b2e",
   "metadata": {},
   "source": [
    "6. Die Projektionen $a_i$ der Daten $\\mathbf{x}_i$ auf die ersten $r$ Basisvektoren $\\mathbf{q}_i$ (d.h die neuen Variablenwerte im neuen Koordinatensystem) sind die die ersten $r$ Spalten der $n \\times d$-Matrix $UD$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X @ Q  # project data onto first r principal components\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56049e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_alt = U[:, :r] * D[:r]  # alternative way using U and D\n",
    "scores_alt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5794551",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(scores, scores_alt), \"Projektionen stimmen nicht überein!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96fcd5",
   "metadata": {},
   "source": [
    "7. Die Standardabweichungen entlang der Hauptkomponenten $\\mathbf{q}_i$ sind die Diagonalelemente der Diagonalmatrix $D$ geteilt durch $\\sqrt{n - 1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_along_pcs = D[:r] / np.sqrt(n - 1)\n",
    "std_along_pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = (D**2) / (n - 1)\n",
    "assert np.allclose(std_along_pcs, np.sqrt(eigvals[:r])), \"Standardabweichungen stimmen nicht überein!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaca64a",
   "metadata": {},
   "source": [
    "Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19cc61",
   "metadata": {},
   "source": [
    "a) Implementieren Sie ein Python-Modul, das eine Funktion zur Hauptkomponentenanalyse nach obigem Schema zur Verfügung stellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pca(X:pd.DataFrame, r:int=3, normalize=True):\n",
    "\t# 1. calculate mean of data array and center\n",
    "\tmean = X.mean()\n",
    "\tX_centered = X - mean\n",
    "\n",
    "\t# 2. normalize if requested\n",
    "\tX_normalized = X_centered / X.std() if normalize else X_centered\n",
    "\n",
    "\t# 3. copy to data/designmatrix\n",
    "\tXd = X_normalized.to_numpy()\n",
    "\n",
    "\t# 4. calculate singular value decomposition\n",
    "\tU, D, Vt = np.linalg.svd(Xd)\n",
    "\tV = Vt.T\n",
    "\n",
    "\t# 5. get r principal components\n",
    "\tQ = V[:, :r]\n",
    "\n",
    "\t# 6. project data onto first r principal components\n",
    "\tA = Xd @ Q\n",
    "\n",
    "\t# 7. calculate standard deviations along principal components\n",
    "\tstd_pcs = D[:r] / np.sqrt(Xd.shape[0] - 1)\n",
    "\n",
    "\treturn Q, A, std_pcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f57c01",
   "metadata": {},
   "source": [
    "b) Testen Sie Ihr Modul innerhalb eines IPython-Notebooks am Datensatz *Boston Housing*. Lassen Sie dabei die Variable `TGT` weg. Stellen Sie Ihre Ergebnisse in einer Tabelle mit den Eigenwerten der Kovarianzmatrix (Achtung: die Diagonalelemente von $D$ müssen dafür quadriert und durch n − 1 geteilt werden. Warum?), dem Anteil der zugehörigen Hauptkomponente an an der Gesamtvarianz (“erklärte Varianz”) und der kumulativen erklärten Varianz dar, d.h. welchen Varianzanteil die ersten $n$ Komponenten zusammen erklären. Wieviele Dimensionen können Sie weglassen, wenn Sie 10%, 5% und 1% Fehler bei der Dimensionsreduktion zulassen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b473e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}, pandas version: {pd.__version__}\")\n",
    "\n",
    "url     = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols    = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B', 'LSTAT','TGT']\n",
    "boston  = pd.read_csv(url, sep=' ', skipinitialspace=True, header=None, names=cols, index_col=False)\n",
    "\n",
    "boston = boston.drop(columns=['TGT'])  # drop target variable\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b27241",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, A, std_pcs = pca(boston, r=boston.shape[1], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4304893",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = (std_pcs ** 2) * (boston.shape[0] - 1)\n",
    "explained_variance = eigenvalues / np.sum(eigenvalues)\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "pca_results = pd.DataFrame({\n",
    "    'Eigenvalue': eigenvalues,\n",
    "    'Explained Variance': explained_variance,\n",
    "    'Cumulative Explained Variance': cumulative_explained_variance\n",
    "})\n",
    "\n",
    "print(pca_results)\n",
    "\n",
    "\n",
    "# Bestimmung der Anzahl der Dimensionen, die weggelassen werden können\n",
    "def dimensions_to_retain(threshold):\n",
    "    return np.argmax(cumulative_explained_variance >= (1 - threshold)) + 1\n",
    "\n",
    "\n",
    "for error in [0.10, 0.05, 0.01]:\n",
    "    dims = dimensions_to_retain(error)\n",
    "    print(f\"Dimensions to retain for {error * 100}% error: {dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e92aa8",
   "metadata": {},
   "source": [
    "c) Berechnen Sie die Matrix der Korrelationskoeffizienten für die transformierten Variablen und interpretieren Sie das Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_A = pd.DataFrame(A).corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_A, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Korrelations-Heatmap der Hauptkomponenten')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1553a7",
   "metadata": {},
   "source": [
    "**Interpretation des Ergebnisses:**\n",
    "Wie in der Heatmap zu sehen sind die Diagonalelemente alle 1 (logisch, da jede Variable perfekt mit sich selbst korreliert ist) und alle anderen Elemente sind 0. Dies deutet darauf hin, dass die Hauptkomponenten unkorreliert sind und somit eine Reduktion der Dimensionalität ohne Informationsverlust möglich ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f4b48",
   "metadata": {},
   "source": [
    "d) Berechnen Sie den Korrelationskoeffizienten der Projektionen auf die ersten drei Hauptkomponenten mit den ursprünglichen Variablen. Interpretieren Sie Ihr Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aebc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = boston_normalized.copy()\n",
    "PCs = pd.DataFrame(A[:,:3], columns=['PC1', 'PC2', 'PC3'])\n",
    "combined = pd.concat([boston_data, PCs], axis=1)\n",
    "corr_pc_orig = combined.corr().loc[PCs.columns, boston_data.columns]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(corr_pc_orig, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Korrelations-Heatmap zwischen Hauptkomponenten und Originalvariablen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267adfdb",
   "metadata": {},
   "source": [
    "e. Stellen Sie die ersten beiden der neuen Variablen als Scatterplot dar (am besten in Pandas-Dataframe importieren). Plotten Sie dabei alle Datenpunkte mit einem Hauspreis oberhalb des Medians aller Hauspreise in einer anderen Farbe als die Datenpunkte unterhalb. Eignen sich die beiden neuen Variablen zur Vorhersage des Hauspreises?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a42406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
